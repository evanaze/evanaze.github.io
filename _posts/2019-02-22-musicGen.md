---
title: "Data Science Project: Music Generation"
date: 2019-02-22
tags: [data science, music, deep learning]
excerpt: "Data Science, music, deep learning"
---


## Inspiration:

Sample output with far less data - <a href="https://www.youtube.com/watch?v=C0cAy3-vryo">https://www.youtube.com/watch?v=C0cAy3-vryo</a>.  
WaveNet group results. Single and multi instrument generated music. <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">https://deepmind.com/blog/wavenet-generative-model-raw-audio/</a>.

## Resources:

Wavenet: <a href="https://github.com/ibab/tensorflow-wavenet">https://github.com/ibab/tensorflow-wavenet</a>

GRUV: <a href="https://github.com/MattVitelli/GRUV">https://github.com/MattVitelli/GRUV</a>

Dataset: Downloaded mixes of low-fi hip hop from YouTube and SoundCloud.

## Dataset

We train our model on a collection of 1,700 tracks downloaded from YouTube and Soundcloud. Songs over 30 minutes have been trimmed into individual tracks to facilite learning. The total dataset is over 35 Gigabytes and all tracks have been converted into .wav files.
Chilled Cow on YouTube streams Low-fi hip-hop, we added streams similar to these into our dataset: <a href="https://www.youtube.com/watch?v=hHW1oY26kxQ">https://www.youtube.com/watch?v=hHW1oY26kxQ</a>.

## Goals of the project:

The goal of this project is to create a program that produces low-fi hip hop music generated by a WaveNet model that is trained on at least 1500 tracks.

## Steps in the project:

1. Download tracks from YouTube and SoundCloud. Saved tracks to a flash drive.
2. Manually trim long tracks in GarageBand that have multiple songs or exceed 30 mins in length.   
3. Convert tracks from .mp3 to .wav using script in GRUV.  
4. Store tracks in S3 (may not be necessary).   
To do:

5. Exploratory data analysis, which we will add to this README.
6. Install all necessary software onto AWS virtual machine, and train WaveNet model using the p2.xlarge through accessing S3 data or via scp transfer.
7. Generate output.  
Extra: Make playlist with output and upload to YouTube and SoundCloud.   
8. Extract insight once we have generated output to talk about in presentation.  

## Current progress

2/22/19

Today we begin uploading the data to the EC2 instance, and will start training.

2/19/19

So far, we have collected all the data we want to use, trimmed it, and converted it to the necessary file formay (.wav). We messed up and set up an instance with the default Amazon Linux machine image instead of the Deep Learning Ubuntu machine image which will have TensorFlow already installed on it. We have access to a p2.xlarge GPU. Right now we are uploading the full data set into S3 but it will take a few hours. This may not be necessary if we can figure out what went wrong with scp our data to the server. We expect to have generated some output by Friday.
